{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ghb0nAUa6CW"
   },
   "source": [
    "# 問題4：疾病画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lotz-z6Eu9Kr"
   },
   "source": [
    "## 取り組む問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5acWcw9tbowt"
   },
   "source": [
    "[Cassava Leaf Disease Classification](https://www.kaggle.com/competitions/cassava-leaf-disease-classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDmdfZjXc4Lf"
   },
   "source": [
    "### 背景\n",
    "\n",
    "キャッサバは世界の多くの地域で主要な主食作物の一つである。その人気の主な理由の一つは、干ばつなどの過酷な条件に対する耐性である。しかし、キャッサバは依然として病気にかかりやすく、作物の収量に大きな影響を与える可能性がある。病気を正しく特定することが治療を成功させる第一歩だが、多くの農家はそのための専門知識が不足している。病害の迅速な特定を可能にするツールは、健全な植物への被害を抑える上で特に有用であろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZ_ngyChcISE"
   },
   "source": [
    "### 課題\n",
    "\n",
    "あなたはキャッサバの植物の画像を与えられ、植物が健康かどうかを判断し、4種類の病気を見分けるという課題を与えられています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKQlE4uujUMh"
   },
   "source": [
    "### データ\n",
    "\n",
    "* `train.csv` - コメントとそのラベルを含むファイル。\n",
    "* `test.csv` - テストデータを含むファイル。\n",
    "* `sample_submission.csv` - サンプル提出ファイルを含むファイルであり、提出ファイルで期待されるカラムを示すために使用される。\n",
    "* `test_labels.csv` - コンペティション終了後に公開されたテストデータのラベル。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skwc9dDjhPpd"
   },
   "source": [
    "### リンク集\n",
    "\n",
    "* [データ解説](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/data)\n",
    "* [1位の解答](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221957)\n",
    "* [2位の解答](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/220898)\n",
    "* [3位の解答](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdb7vTdWFpRK"
   },
   "source": [
    "## セットアップ\n",
    "\n",
    "以下のセルは必要なデータをダウンロードし、ノートブックで使用する環境を設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyRs9VaFUYxX"
   },
   "source": [
    "### GPUランタイム\n",
    "\n",
    "このノートブックはGPUを搭載したシステムで実行するように設計されています．ランタイムのタイプをGPUを含むものに切り替えていることを確認してください（例：A100，V100）．\n",
    "\n",
    "GPUランタイムを使用しているかどうかを確認するには，次のセルを実行してください．フォーマットされたテキストが複数行出力されるはずです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zptW1nfWOt-U"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmLHHzThvYOe"
   },
   "source": [
    "### データセット\n",
    "\n",
    "Kaggleはコンペティションと簡単にやり取りできるAPIを提供しています．このAPIを使ってデータをダウンロードし，予測結果をアップロードします．\n",
    "\n",
    "このAPIを使用する最初のステップは，ユーザー認証です．APIトークンはユーザー名とKaggleが生成したキーを含むファイルです．トークンはアカウントページからダウンロードすることができ，通常 `kaggle.json` という名前のファイルです．APIトークンは，ユーザーとしてAPIにアクセスするために必要なものなので，個人のGoogle Driveフォルダに安全に保管してください．\n",
    "\n",
    "このノートブックはGoogle Driveフォルダ内の`kaggle.json`というKaggle APIトークンを検索します．トークンをGoogle Driveに置いたことを確認し，プロンプトが表示されたらこのノートブックがトークンにアクセスすることを許可してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQD2G6we26Uc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import json\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "fin = open(\"/content/drive/MyDrive/kaggle.json\", \"r\")\n",
    "json_data = json.load(fin)\n",
    "fin.close()\n",
    "os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n",
    "os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF4iMwYMisPA"
   },
   "source": [
    "データが大きいため、ダウンロードと解凍に数分かかる場合があります。認証後，参加したすべてのコンペティションにアクセスできます．データのダウンロードにエラーが発生した場合は，Kaggle API トークンが有効であること，コンペティションのルールに同意していることを確認してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlP34vuZ3ROs"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "kaggle competitions download -c cassava-leaf-disease-classification\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"データのダウンロードに問題があったようです。\"\n",
    "    echo \"競技規則に同意し、APIキーが有効であることを確認してください。\"\n",
    "else\n",
    "    mkdir -p /content/kaggle\n",
    "    unzip -q -o /content/cassava-leaf-disease-classification.zip -d /content/kaggle\n",
    "fi\n",
    "wget -q -P /tmp https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip\n",
    "unzip -o /tmp/NotoSansCJKjp-hinted.zip -d /usr/share/fonts/NotoSansCJKjp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntxzZOlbGXX9"
   },
   "source": [
    "### 環境\n",
    "\n",
    "デフォルトではインストールされていないライブラリを使用するので、ここでインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ2JUIe5QuiK"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-NnydfZGhXs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics\n",
    "from glob import glob\n",
    "import json\n",
    "from PIL import Image\n",
    "import multiprocessing as mp\n",
    "import torchvision\n",
    "import timm\n",
    "\n",
    "font_path = '/usr/share/fonts/NotoSansCJKjp/NotoSansMonoCJKjp-Regular.otf'\n",
    "matplotlib.font_manager.fontManager.addfont(font_path)\n",
    "prop = matplotlib.font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = prop.get_name()\n",
    "os.chdir('/content/kaggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnE-3PKRHFzM"
   },
   "source": [
    "## 探索的データ解析\n",
    "\n",
    "このコンペティションでは、植物の画像と病気の存在を示すラベルが与えられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e6U3QDEGae2"
   },
   "source": [
    "### label_num_to_disease_map.json\n",
    "\n",
    "トレーニングデータで提供されるラベルは数値です。このファイルはラベルから病名へのマッピングを提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0yHXszhGZ7K"
   },
   "outputs": [],
   "source": [
    "with open('label_num_to_disease_map.json', 'r') as fh:\n",
    "    diseases = json.loads(fh.read())\n",
    "diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7Vzmd51IsMg"
   },
   "source": [
    "### train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcueI2pt3Re4"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/kaggle/train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GxHkbeuJsEK"
   },
   "source": [
    "このファイルは単にファイル名とそれに対応するラベルのリストである。\n",
    "\n",
    "まず、それぞれの病気の例を健康な植物とともに見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zJWSMsFH7F4"
   },
   "outputs": [],
   "source": [
    "for label, disease in diseases.items():\n",
    "    plt.figure()\n",
    "    filename = data[data['label']==int(label)].sample(1)['image_id'].values[0]\n",
    "    with Image.open(f'train_images/{filename}') as image:\n",
    "        plt.imshow(image)\n",
    "        plt.title(disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM4ymEv0VvKl"
   },
   "source": [
    "次にラベルの分布を見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OE_Qq-O4I82w"
   },
   "outputs": [],
   "source": [
    "data_bar = data.copy()\n",
    "data_bar.loc[data_bar['label']==0, 'label'] = 'Cassava\\n Bacterial\\nBlight'\n",
    "data_bar.loc[data_bar['label']==1, 'label'] = 'Cassava\\nBrown\\nStreak\\nDisease'\n",
    "data_bar.loc[data_bar['label']==2, 'label'] = 'Cassava\\nGreen\\nMottle'\n",
    "data_bar.loc[data_bar['label']==3, 'label'] = 'Cassava\\nMosaic\\nDisease'\n",
    "data_bar.loc[data_bar['label']==4, 'label'] = 'Healthy'\n",
    "sns.countplot(data_bar, x='label')\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT_MXNNxJ3GH"
   },
   "source": [
    "分類タスクの多くの場合とは異なり、「健康な」クラスが最も一般的なクラスではないことがわかる。実際、`カッサバ・モザイク病`は、他のすべてのクラスを合わせたのと同じくらい頻度が高いように見える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV6dGHtQRMQ9"
   },
   "source": [
    "## モデリング\n",
    "\n",
    "このノートでは、画像分類タスクでよく使われる画像モデルEfficientNetを使います。モデルと事前学習された重みは `timm` ライブラリから読み込みます。PyTorchとPyTorch Lightningも使います。PyTorchはディープラーニングでよく使われるライブラリで、モデルの作成と学習ができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmQo45a9ROa4"
   },
   "source": [
    "### 前処理\n",
    "\n",
    "トレーニング用のデータセットを準備するために必要な前処理はあまりありません。単純に画像をファイルから読み込み、サイズを小さくするだけです。\n",
    "\n",
    "データセットは約7GBとそれほど大きくはありませんが、一度にメモリにロードするには時間がかかるかもしれません。さらに、ディスク上の画像は圧縮されており、一度読み込まれたデータのサイズは7GBより大きくなる可能性が高い。長時間の前処理を避け、メモリエラーのリスクを減らすために、PyTorch の `DataSet` オブジェクトを介してアクセスされた画像を読み込みます。\n",
    "\n",
    "High-RAM オプションを有効にした A100 ランタイムタイプを選択していることを確認してください。この組み合わせにより、多くのプロセッサを持つシステムを利用できるようになり、多くの画像を並列処理することでオンザフライ処理のコストを相殺することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XheedOPAUvfr"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filenames, labels=None):\n",
    "        if labels is not None:\n",
    "            self.labels = torch.nn.functional.one_hot(torch.tensor(labels), num_classes=5).float()\n",
    "        else:\n",
    "            self.labels = None\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        with Image.open(f'train_images/{filename}') as pil_image:\n",
    "            image = torchvision.transforms.functional.pil_to_tensor(pil_image)\n",
    "        image = torchvision.transforms.functional.resize(image, (256, 256), antialias=True)\n",
    "        image = image.float() / 255\n",
    "        if self.labels is None:\n",
    "            return image\n",
    "        else:\n",
    "            return image, self.labels[idx]\n",
    "\n",
    "ds = CustomDataset(data['image_id'].values, data['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH_GRDYHPSrl"
   },
   "source": [
    "### トレーニング\n",
    "\n",
    "今回使用するモデルは、別のタスクのためにすでに学習済みです。単にモデルを初期化し、データセットのクラスの値を出力するように変更します。その後、モデルを微調整し、タスクのためにモデルを再トレーニングします。\n",
    "\n",
    "標準的なPyTorchでは、モデルやタスクに関係なく同じテンプレートコードを書きます。これは非常に面倒であり、また細かい部分を忘れやすいためエラーが起こりやすい。PyTorch Lightningを使えば、学習コードの最も関連性の高い部分を1つのクラスにまとめ、細かい部分はライブラリに任せることができます。さらに、PyTorch Lightningはロギング、チェックポイント、その他のタスクのための多くの便利なユーティリティを提供します。\n",
    "\n",
    "以下のセルでは、以下のメソッドを含む PyTorch Lightning の `LightningModule` を定義します：\n",
    "- `__init__` - 学習中に使用する変数を初期化します。これにはモデルとトレーニングの進捗を監視するためのメトリクスが含まれます。\n",
    "- `forward` - 与えられた入力をどのようにモデルに渡すかを定義する。\n",
    "- `(training|validation)_step` - 各ステップで実行するアクションを定義します。最も単純なケースでは `forward` を呼び出して損失を計算するが、追加の後処理やロギングを含めることもできる。\n",
    "- `configure_optimizers` - トレーニング中に使用するオプティマイザを返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIhvXRUvam3t"
   },
   "outputs": [],
   "source": [
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-5):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.train_accuracy = torchmetrics.classification.MulticlassAccuracy(num_classes=5)\n",
    "        self.val_accuracy = torchmetrics.classification.MulticlassAccuracy(num_classes=5)\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image, labels = batch\n",
    "        preds = self.forward(image)\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.train_accuracy(preds.softmax(1), labels.argmax(1))\n",
    "        self.log('train_accuracy', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image, labels = batch\n",
    "        preds = self.forward(image)\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.val_accuracy(preds.softmax(1), labels.argmax(1))\n",
    "        self.log('val_accuracy', self.val_accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M12xhzMaJVqP"
   },
   "source": [
    "モデルが学習しているかどうかを確認するには、トレーニング中のパフォーマンスをモニターする必要がある。具体的には、時間の経過とともに損失が減少していること、追跡しているメトリクスに改善が見られることを確認したい。\n",
    "\n",
    "ここでは、TensorBoardを使用してトレーニングを監視します。TensorBoardは、時間の経過とともにモデルのパフォーマンスを可視化する便利なツールです。\n",
    "\n",
    "TensorBoardサーバーを起動するには、以下のセルを実行します。数秒後、インターフェースが表示されます。トレーニングやロギング値を開始していないため、最初は何も出力されません。トレーニングが開始されると、セルの出力は定期的に更新されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHpyCHfzCfsT"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBEeQvJ1JiQx"
   },
   "source": [
    "トレーニングの準備はほぼ整いました。次のセルでは、まずデータを学習セットと検証セットに分割し、データをバッチ処理するPyTorchの `DataLoader` を準備します。次に、モデルとロガーを初期化し、モデルの最適な反復を保存するコールバックを作成します。最後に、学習を開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5q3nesc6tiK"
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds = torch.utils.data.random_split(ds, [0.8, 0.2])\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=mp.cpu_count())\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=mp.cpu_count())\n",
    "\n",
    "model = CustomModel()\n",
    "tb_logger = pl.loggers.TensorBoardLogger('lightning_logs', name='', version='custom_model')\n",
    "if os.path.exists(f'lightning_logs/{tb_logger.version}/checkpoints'):\n",
    "    for checkpoint in os.listdir(f'lightning_logs/{tb_logger.version}/checkpoints/'):\n",
    "        os.remove(f'lightning_logs/{tb_logger.version}/checkpoints/{checkpoint}')\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_accuracy', mode='max')\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, accelerator='gpu', precision='16-mixed',\n",
    "    logger=tb_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG525n1dNuag"
   },
   "source": [
    "### Kaggleへのアップロード\n",
    "\n",
    "このコンペティションは「カーネルコンペティション」であり、テストデータに直接アクセスすることはできません。代わりに、競技者は完全なテストデータを含む環境でKaggleによって実行されるコードを提出することが期待されています。これはコンペティションをより公平にするために行われていることですが、システムに慣れていない参加者にとっては混乱や複雑さを引き起こす可能性があります。\n",
    "\n",
    "この種のコンペティションでよく行われるのは\n",
    "1. 競技データでモデルをトレーニングする。\n",
    "2. トレーニングしたモデルをデータセットとしてKaggleにアップロードする。\n",
    "3. Kaggle上でデータセットから学習済みモデルをロードするノートブックを作成する。\n",
    "4. データセットを更新する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dq5wt6GBy353"
   },
   "source": [
    "#### ステップ1\n",
    "\n",
    "学習済みモデルのアップロードをします．前のセルでモデルをトレーニングしたので、モデルのアップロードに移ります。次のセルでは、Kaggle APIを使ってプライベートデータセットを自動的に作成し、アップロードします。このセルを続けて実行すると、データセットが更新されます。\n",
    "\n",
    "Kaggle APIはあなたのデータセットへのリンクを出力します。それをクリックしてデータセットにアクセスし、正常に作成されたことを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiN-Vc9lNjHe"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dataset_name=\"cassava-project-dataset-$KAGGLE_USERNAME\"\n",
    "dataset_dir=\"/content/kaggle/$dataset_name\"\n",
    "dataset_meta_path=\"$dataset_dir/dataset-metadata.json\"\n",
    "mkdir -p \"$dataset_dir\"\n",
    "cp lightning_logs/custom_model/checkpoints/*.ckpt \"$dataset_dir/checkpoint.ckpt\"\n",
    "kaggle datasets init -p \"$dataset_dir\"\n",
    "sed -i \"s/INSERT_TITLE_HERE/$dataset_name/g\" \"$dataset_meta_path\"\n",
    "sed -i \"s/INSERT_SLUG_HERE/$dataset_name/g\" \"$dataset_meta_path\"\n",
    "dataset_exists=$(kaggle datasets list -m -s \"$dataset_name\" | grep \"$dataset_name\")\n",
    "dataset_exists=$?\n",
    "if [ $dataset_exists -eq \"0\" ]\n",
    "then\n",
    "    echo \"Updating dataset\"\n",
    "    kaggle datasets version -p \"$dataset_dir\" -m \"Version message\"\n",
    "else\n",
    "    echo \"Creating dataset\"\n",
    "    kaggle datasets create -p \"$dataset_dir\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py7hn2E6x_5d"
   },
   "source": [
    "#### ステップ2\n",
    "\n",
    "競技用ノートブックを作成します．学習済みモデルを含むデータセットを作成した後、競技会用のノートブックを作成します。\n",
    "\n",
    "[このリンク](https://www.kaggle.com/competitions/cassava-leaf-disease-classification)をクリックすると、競技会場に移動します。\n",
    "\n",
    "以下の画像を参考にノートブックを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0ARcuZjRzMp"
   },
   "source": [
    "「Late Submission」をクリックして。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-01.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYj00TH30mj6"
   },
   "source": [
    "「New Notebook」をクリックします。\n",
    "\n",
    "新しいノートブックが別のタブで開きます。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-02.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwPimL6AG7DI"
   },
   "source": [
    "ノートブックにはKaggleによって生成された名前とテンプレートコードがあります。ノートブックの名前をもっと分かりやすいものに変更することをお勧めしますが、そのままでも問題ありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES_3ZBgj1lqf"
   },
   "source": [
    "「Add Data」をクリックして。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-03.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7-Kt3i73hup"
   },
   "source": [
    "データセットには、`cassava-project-dataset-KAGGLE_USERNAME` のような名前が付けられているはずです。データセットのリストの一番上にあるはずですが、ない場合は「Your Datasets」をクリックすると表示されます。\n",
    "\n",
    "「＋」をクリックしてデータセットを添付する。\n",
    "\n",
    "次に、「X」をクリックして、「Add Data」タブを閉じる。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-04.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuZkrZhuGiMX"
   },
   "source": [
    "データセットが正常に追加されたことを確認します。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-05.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlsB9WQEG2GP"
   },
   "source": [
    "ノートブックのテンプレート・コードをすべて削除してください。空のコード・セルが残るはずです。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-06.png?raw=1\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcOlM7jLKkNa"
   },
   "source": [
    "下のセルは、このノートブックで以前に作成したデータセットを使うようにカスタマイズされたパイソンコードを出力します。\n",
    "\n",
    "このコードは基本的にこのノートブックのコードを凝縮し、少し修正したものです。トレーニングの代わりに、以下のコードはデータセットに含まれるモデルのチェックポイントをロードします。次にテスト画像をロードし、各疾患クラスの予測を生成します。最後に、予測値をファイル `submission.csv` に書き込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isXU8tFhWxlI"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dataset_name=\"cassava-project-dataset-$KAGGLE_USERNAME\"\n",
    "cat << EOF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image\n",
    "import multiprocessing as mp\n",
    "import torchvision\n",
    "import timm\n",
    "\n",
    "test_filenames = os.listdir('/kaggle/input/cassava-leaf-disease-classification/test_images')\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filenames, labels=None):\n",
    "        if labels is not None:\n",
    "            self.labels = torch.nn.functional.one_hot(torch.tensor(labels), num_classes=5).float()\n",
    "        else:\n",
    "            self.labels = None\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        with Image.open(f'/kaggle/input/cassava-leaf-disease-classification/test_images/{filename}') as pil_image:\n",
    "            image = torchvision.transforms.functional.pil_to_tensor(pil_image)\n",
    "        image = torchvision.transforms.functional.resize(image, (256, 256), antialias=True)\n",
    "        image = image.float() / 255\n",
    "        if self.labels is None:\n",
    "            return image\n",
    "        else:\n",
    "            return image, self.labels[idx]\n",
    "\n",
    "ds = CustomDataset(test_filenames)\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=5)\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        preds = self.forward(batch).softmax(1).argmax(1).detach().cpu()\n",
    "        return preds\n",
    "\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=False, num_workers=mp.cpu_count())\n",
    "\n",
    "model = CustomModel.load_from_checkpoint('/kaggle/input/$dataset_name/checkpoint.ckpt')\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', precision='16-mixed',\n",
    "    logger=None, callbacks=None\n",
    ")\n",
    "\n",
    "preds = trainer.predict(model, dl)\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'image_id': test_filenames,\n",
    "    'label': torch.cat(preds).numpy()\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFkSndhQNLKL"
   },
   "source": [
    "上記の出力をKaggleノートブックにコピーします。すべての行をコピーするには、必要に応じてスクロールしてください。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-07.png?raw=1\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw9M-Ux_NXFb"
   },
   "source": [
    "次に、GPUをノートブックで使えるようにし、インターネットアクセスを無効にする必要がある。これらのオプションはノートブックの右側、データタブの下にあります。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-08.png?raw=1\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQTngJIrkU6b"
   },
   "source": [
    "これでノートブックはセットアップされ、コンペティションに提出する準備が整いました。コンペティションに提出」セクションに移動し、「Submit」をクリックします。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-09.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9rEoe9JQHma"
   },
   "source": [
    "必要であれば、バージョン名と投稿の説明を入力してください。\n",
    "\n",
    "「Submit」をクリックしてください。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-10.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW_0JOYQQzW3"
   },
   "source": [
    "送信をクリックした後、ノートブックが正常に実行されることを確認するために、ノートブックが一度実行されます。正常に実行された場合は、全テストデータにアクセスできるコンペティション環境で再実行されます。\n",
    "\n",
    "競技会の [提出ページ](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/submissions) をチェックして、あなたの提出物がどのように得点されたかを確認してください。投稿がページに表示され、実行が完了するまで数分かかる場合があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waSbzcyrvhyh"
   },
   "source": [
    "#### ステップ4\n",
    "\n",
    "より高いスコアを得るために、あなたはおそらくモデルをさらに微調整してコンペティションに再提出するでしょう。そのためには、プライベートデータセットを新しい重みで更新し、新しいモデルを使うように競技用ノートブックを設定しなければなりません。\n",
    "\n",
    "ノートブックを更新する際には、以下の画像を参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mmhWdSnxHqp"
   },
   "source": [
    "まず、「学習済みモデルのアップロード」セクションの最初に戻り、モデルのチェックポイントをKaggleにアップロードするコードを実行します。これにより、最新のモデル重みでデータセットが自動的に更新されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qX3b-wzByTky"
   },
   "source": [
    "次に、コンペノートブックを最新モデルにアップデートする必要があります。\n",
    "\n",
    "[コンペティションの投稿ページ](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/submissions)を開いてください。\n",
    "\n",
    "あなたのノートブックの最新の投稿を見つけ、それをクリックして投稿されたバージョンのノートブックに移動します。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-11.png?raw=1\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UVZz0kgz5Jx"
   },
   "source": [
    "「Edit」をクリックして。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-12.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2ZHTxQL0imA"
   },
   "source": [
    "ノートブックが編集モードになります。\n",
    "\n",
    "画面の右側の「Data」タブで、データセットを探してください。データセット名の上にカーソルを置き、縦に3つの点が表示されたら、それをクリックしてください。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-13.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgAARt3w1EYA"
   },
   "source": [
    "「Check for updates」をクリックして。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-14.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ConANTot1WBw"
   },
   "source": [
    "「Update」をクリックして。\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/dxi-kaggle/blob/main/image/kaggle-problem-4-15.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hENO-BD7dHh"
   },
   "source": [
    "あなたのノートブックでは、最新バージョンのデータセットが使用されます。\n",
    "\n",
    "モデルのアーキテクチャやデータの前処理方法を変更した場合は、競技用ノートブックの対応するコードも変更する必要があります。\n",
    "\n",
    "最後に、ノートブックを提出するには、「Submit」 ボタンをクリックし、「競技用ノートブックの作成」 の最後にある手順に従ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIcLceBRoLIz"
   },
   "source": [
    "## 性能向上のための提案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNWxUuHPv56i"
   },
   "source": [
    "### 他のモデル\n",
    "EfficientNetはかなり古いモデルで、私たちが使っているバージョンは一番小さいものです。より大きなEfficientNetsや全く別のモデルに変更することで、精度が向上するかもしれませんが、単純なモデルでもまだ許容できる精度を達成することができます。モデルのサイズとトレーニングに必要なリソースの量を考慮しながら、様々なモデルを試し、パフォーマンスを比較することは興味深いかもしれません。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqbBfAq1v_cr"
   },
   "source": [
    "### 学習率\n",
    "我々の学習率は比較的小さい。これはスコアが悪くなるオーバーフィッティングを避けるのに役立つかもしれませんが、トレーニング時間が長くなります。学習結果を観察し、学習率を上げてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXA2HYMZwDZD"
   },
   "source": [
    "### エポック\n",
    "我々のモデルは数エポックしか学習しません。TensorBoardでトレーニングの進捗を確認すると、検証損失やメトリクスが着実に向上しているように見えますが、これはもっとトレーニングすべき指標です。エポック数を増やしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAxp0zw5wIGN"
   },
   "source": [
    "### 自動的に学習を停止する\n",
    "多くのエポック数を学習すると、モデルの改善が止まってしまう可能性があります。PyTorch Lightning には、学習を早期に終了させる早期停止コールバックがあります。[ドキュメント](https://lightning.ai/docs/pytorch/stable/common/early_stopping.html)を確認して、学習プロセスに追加できるか確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWceXwQMwMH9"
   },
   "source": [
    "### データ補強\n",
    "データ補強と変換は、既存の画像から \"新しい \"画像を作成することで、オーバーフィッティングを減らし、画像データのパフォーマンスを向上させる方法の1つです。例えば、画像を軸に沿って反転させたり、ランダムなノイズを加えたり、トリミングすることで画像を変更することができます。データ補強により、より複雑なモデルを使用しやすくなる場合もありますし、単純に現在のモデルのスコアが向上する場合もあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4voaTqVFmYQz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}