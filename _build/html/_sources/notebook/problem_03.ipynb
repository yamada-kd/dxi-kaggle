{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5acWcw9tbowt"
      },
      "source": [
        "# <font color='#3E1485'>**Toxic Comment Classification Challenge**</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDmdfZjXc4Lf"
      },
      "source": [
        "## <font color='#9271C3'>背景</font>\n",
        "\n",
        "多くのオンラインウェブサイト、アプリケーション、サービスでは、ディスカッション、コメント、その他の目的でユーザーがテキストを入力することができます。ほとんどの場合、私たちはユーザーが適切に行動し、テキスト機能を乱用しないことを期待しています。しかし、時には意図的であろうとなかろうと、ユーザーが会話に貢献しないものを入力し、他の人の体験を悪化させる結果になりかねません。\n",
        "\n",
        "この種のチャット・サービスを運営する多くの事業体にとって、会話を監視するための自動化ツールは需要が高い。有害な言葉を識別するためのそのようなツールは、すべてのユーザーにとってより良い、より一貫性のあるエクスペリエンスにつながるだろう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ_ngyChcISE"
      },
      "source": [
        "## <font color='#9271C3'>タスク</font>\n",
        "\n",
        "Wikipediaから収集されたコメントが提供される。様々なタイプの有害コメントを区別できるモデルを訓練せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQlE4uujUMh"
      },
      "source": [
        "## <font color='#9271C3'>データ</font>\n",
        "\n",
        "* `train.csv` - コメントとそのラベルを含むファイル。\n",
        "* `test.csv` - テストデータを含むファイル。\n",
        "* `sample_submission.csv` - サンプル提出ファイルを含むファイルであり、提出ファイルで期待されるカラムを示すために使用される。\n",
        "* `test_labels.csv` - コンペティション終了後に公開されたテストデータのラベル。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwc9dDjhPpd"
      },
      "source": [
        "## <font color='#9271C3'>お役立ちリンク集</font>\n",
        "\n",
        "[コンペHP](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge)\n",
        "\n",
        "[データ解説](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data)\n",
        "\n",
        "[1位解答](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/discussion/52557)\n",
        "\n",
        "[2位解答](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/discussion/52612)\n",
        "\n",
        "[3位解答](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/discussion/52762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdb7vTdWFpRK"
      },
      "source": [
        "# <font color='#3E1485'>**セットアップ**</font>\n",
        "\n",
        "以下のセルは必要なデータをダウンロードし、ノートブックで使用する環境を設定します。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#9271C3'>GPUランタイムを有効にする</font>\n",
        "\n",
        "このノートブックはGPUを搭載したシステムで実行するように設計されています。ランタイムのタイプをGPUを含むものに切り替えていることを確認してください（例：A100、V100）。\n",
        "\n",
        "GPUランタイムを使用しているかどうかを確認するには、次のセルを実行してください。フォーマットされたテキストが複数行出力されるはずです。"
      ],
      "metadata": {
        "id": "QyRs9VaFUYxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "NF9kwurFU8IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whJ4QYr6Fsbq"
      },
      "source": [
        "## <font color='#9271C3'>データセットをダウンロードする</font>\n",
        "\n",
        "Kaggleはコンペティションと簡単にやり取りできるAPIを提供しています。私たちはこのAPIを使って自動的にデータをダウンロードし、予測をアップロードします。\n",
        "\n",
        "このAPIを使用する最初のステップは、自分のユーザーとして認証することです。APIトークンはユーザー名とKaggleが生成したキーを含むファイルです。トークンはアカウントページからダウンロードすることができ、通常 `kaggle.json` と呼ばれます。APIトークンは、あなたのユーザーとしてAPIにアクセスするために必要なものなので、個人のGoogle Driveフォルダに安全に保管してください。\n",
        "\n",
        "このノートブックはGoogle Driveフォルダ内の`kaggle.json`というKaggle APIトークンを検索します。トークンをGoogle Driveに置いたことを確認し、プロンプトが表示されたらこのノートブックがトークンにアクセスすることを許可してください。\n",
        "\n",
        "認証後、参加したすべてのコンペティションにアクセスできます。データのダウンロードにエラーが発生した場合は、Kaggle API トークンが有効であること、コンペティションのルールに同意していることを確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQD2G6we26Uc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "fin = open(\"/content/drive/MyDrive/kaggle.json\", \"r\")\n",
        "json_data = json.load(fin)\n",
        "fin.close()\n",
        "os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n",
        "os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlP34vuZ3ROs"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "if [ $? -ne 0 ]; then\n",
        "    echo \"データのダウンロードに問題があったようです。\"\n",
        "    echo \"競技規則に同意し、APIキーが有効であることを確認してください。\"\n",
        "else\n",
        "    mkdir -p /content/kaggle\n",
        "    unzip -o /content/jigsaw-toxic-comment-classification-challenge.zip -d /content/kaggle\n",
        "    unzip -o \"/content/kaggle/*.zip\" -d /content/kaggle\n",
        "    rm /content/kaggle/*.zip\n",
        "fi\n",
        "wget -q -P /tmp https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip\n",
        "unzip -o /tmp/NotoSansCJKjp-hinted.zip -d /usr/share/fonts/NotoSansCJKjp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntxzZOlbGXX9"
      },
      "source": [
        "## <font color='#9271C3'>環境</font>\n",
        "\n",
        "デフォルトではインストールされていないライブラリを使用するので、ここでインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pytorch-lightning"
      ],
      "metadata": {
        "id": "ZZ2JUIe5QuiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-NnydfZGhXs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from tqdm.auto import tqdm\n",
        "import torchmetrics\n",
        "from glob import glob\n",
        "\n",
        "font_path = '/usr/share/fonts/NotoSansCJKjp/NotoSansMonoCJKjp-Regular.otf'\n",
        "matplotlib.font_manager.fontManager.addfont(font_path)\n",
        "prop = matplotlib.font_manager.FontProperties(fname=font_path)\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = prop.get_name()\n",
        "os.chdir('/content/kaggle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnE-3PKRHFzM"
      },
      "source": [
        "# <font color='#3E1485'>**視覚化**</font>\n",
        "\n",
        "この大会のデータはコメントとそのラベルで構成されている。可視化できるものはあまりありませんが、ラベルの分布といくつかの有害なコメントを見ることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7Vzmd51IsMg"
      },
      "source": [
        "## <font color='#9271C3'>train.csv</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcueI2pt3Re4"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/kaggle/train.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM4ymEv0VvKl"
      },
      "source": [
        "まず、ラベルの分布を見てみよう。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_bin = data.copy()\n",
        "data_bin['non-toxic'] = 1 - data_bin[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n",
        "data_bin['toxic'] = data_bin[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n",
        "data_bin = data_bin[['id', 'toxic', 'non-toxic']].melt(id_vars='id')\n",
        "sns.barplot(data_bin, x='variable', y='value', errorbar=None)\n",
        "plt.xlabel(None)\n",
        "plt.ylabel(None)\n",
        "plt.xticks([0, 1], ['Toxic', 'Non-toxic']);"
      ],
      "metadata": {
        "id": "OE_Qq-O4I82w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この図から、有害と分類されるコメントは全体の10％程度であることがわかる。"
      ],
      "metadata": {
        "id": "uT_MXNNxJ3GH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMPKfDT0YBeh"
      },
      "outputs": [],
      "source": [
        "data_melt = data.copy()\n",
        "data_melt = data_melt.drop(columns=['comment_text']).melt(id_vars='id')\n",
        "sns.barplot(data_melt, x='variable', y='value', estimator='sum', errorbar=None)\n",
        "plt.xlabel(None)\n",
        "plt.ylabel(None);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "有害なコメントの種類は同じ頻度ではない。"
      ],
      "metadata": {
        "id": "tXDHGMT5LOnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_sum = data.copy()\n",
        "data_sum['num_labels'] = data_sum[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
        "data_sum = data_sum[data_sum['num_labels']>0]\n",
        "sns.barplot(data_sum, x='num_labels', y='num_labels', estimator='count', errorbar=None)\n",
        "plt.ylabel(None);"
      ],
      "metadata": {
        "id": "rpZR87fvIlJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "毒性クラスが通常より多く表示される理由のひとつは、毒性クラスが最も一般的な分類であり、コメントによっては複数の毒性タイプが含まれているからかもしれない。"
      ],
      "metadata": {
        "id": "c269J49TODlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "有害なコメントを見てみよう。"
      ],
      "metadata": {
        "id": "-K1DRV8XOGK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obscene = data.loc[67329]\n",
        "obscene['comment_text']"
      ],
      "metadata": {
        "id": "PnMq_HODOPJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコメントはわいせつに分類されます。わいせつなコメントには通常、閲覧者によっては不適切と思われる言葉が含まれています。"
      ],
      "metadata": {
        "id": "CLix7P16PF6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insult = data.loc[106700]\n",
        "insult['comment_text']"
      ],
      "metadata": {
        "id": "ArmLL2lFPs7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコメントは侮辱に分類される。侮辱は通常、1人または複数の人に向けられ、軽蔑や軽蔑を伝えます。"
      ],
      "metadata": {
        "id": "uFUelnZ3P4Te"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV6dGHtQRMQ9"
      },
      "source": [
        "# <font color='#3E1485'>**モデリング**</font>\n",
        "\n",
        "このノートブックでは、2018年に導入された人気の言語モデルであるBERTを使用します。また、HuggingFaceの`transformers` ライブラリも利用します。これは、事前に学習されたBERTモデルと、テキストデータを前処理するための様々なユーティリティを提供します。最後に、PyTorchとPyTorch Lightningを使用します。PyTorchとPyTorch Lightningは、モデルの作成と学習を可能にするディープラーニングによく使用されるライブラリです。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#9271C3'>前処理</font>\n",
        "\n",
        "BERT のようなモデルを使用するには、まず入力をトークン化する必要があります。これは単にテキストを BERT が理解できる数値に変換することを意味します。`transformers`は自動的に正しいトークナイザーを読み込む`AutoTokenizer`クラスを提供する。\n",
        "\n",
        "次に、学習中に使用できる構造化された方法でデータを整理する必要があります。そのために、PyTorchの `Dataset` を使います。この `Dataset` はモデルとデータの間のインターフェイスとして機能します。\n",
        "\n",
        "このコンペティションのデータセットは小さいので、すべてのトレーニングデータセットを前処理してメモリに保存することができます。そうすることで、データをその場でトークン化するのではなく、事前にトークン化されたデータをメモリからロードするため、トレーニングが大幅にスピードアップする。\n",
        "\n",
        "トレーニングの後半では、データサンプルをバッチ処理する。簡単のため、トークナイザーが返す最初の128個のトークンのみを使用します。それ以上のトークンを持つテキストは切り捨てられ、それ以下のトークンを持つテキストはパディングされます。パラメータ `max_length` を変更すると、トークン化された入力により多くの情報が含まれるようになりますが、その分メモリのコストが増加します。\n",
        "\n",
        "前処理には数分かかるかもしれない。"
      ],
      "metadata": {
        "id": "fmQo45a9ROa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, comments, labels=None):\n",
        "        self.tokenized = []\n",
        "        if labels is not None:\n",
        "            self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "        else:\n",
        "            self.labels = None\n",
        "        print('データのトークン化')\n",
        "        for comment in tqdm(comments):\n",
        "            self.tokenized.append({\n",
        "                key: value[0] for key, value in\n",
        "                    tokenizer(\n",
        "                        comment,\n",
        "                        return_tensors='pt',\n",
        "                        padding='max_length',\n",
        "                        truncation=True,\n",
        "                        max_length=128\n",
        "                    ).items()\n",
        "            })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is None:\n",
        "            return self.tokenized[idx]\n",
        "        else:\n",
        "            return self.tokenized[idx], self.labels[idx]\n",
        "\n",
        "ds = CustomDataset(tokenizer, data['comment_text'], data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)"
      ],
      "metadata": {
        "id": "XheedOPAUvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH_GRDYHPSrl"
      },
      "source": [
        "## <font color='#9271C3'>トレーニング</font>\n",
        "\n",
        "今回使用するBERTモデルは、別のタスクのためにすでに訓練されています。単にモデルを初期化し、データセットのクラスの値を出力するように変更します。その後、モデルを微調整し、タスクのためにモデルを再トレーニングします。\n",
        "\n",
        "標準的なPyTorchでは、モデルやタスクに関係なく同じテンプレートコードを書きます。これは非常に面倒であり、また細かい部分を忘れやすいためエラーが起こりやすい。PyTorch Lightningを使えば、学習コードの最も関連性の高い部分を1つのクラスにまとめ、細かい部分はライブラリに任せることができます。さらに、PyTorch Lightningはロギング、チェックポイント、その他のタスクのための多くの便利なユーティリティを提供します。\n",
        "\n",
        "以下のセルでは、以下のメソッドを含む PyTorch Lightning `LightningModule` を定義します：\n",
        "- `__init__` - 学習中に使用する変数を初期化します。これにはモデルとトレーニングの進捗を監視するためのメトリクスが含まれます。\n",
        "- `forward` - 与えられた入力をどのようにモデルに渡すかを定義する。\n",
        "- `(training|validation|predict)_step` - 各ステップで実行するアクションを定義します。最も単純なケースでは `forward` を呼び出して損失を計算するが、追加の後処理やロギングを含めることもできる。\n",
        "- `configure_optimizers` - トレーニング中に使用するオプティマイザを返す。\n",
        "\n",
        "学習を高速化し、オーバーフィッティングを回避するために、既に学習済みのモデルのパラメータは学習しない。学習されるのは、分類タスク用に作成されたパラメータのみである。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(pl.LightningModule):\n",
        "    def __init__(self, freeze_pretrained=True, lr=1e-5):\n",
        "        super().__init__()\n",
        "        self.lr = lr\n",
        "        self.model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "        if freeze_pretrained:\n",
        "            for name, parameter in self.model.named_parameters():\n",
        "                if 'classifier' not in name:\n",
        "                    parameter.requires_grad = False\n",
        "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "        self.train_AUROC = torchmetrics.classification.MultilabelAUROC(num_labels=6)\n",
        "        self.val_AUROC = torchmetrics.classification.MultilabelAUROC(num_labels=6)\n",
        "\n",
        "    def forward(self, tokenized_input):\n",
        "        return self.model(**tokenized_input)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        tokenized_input, labels = batch\n",
        "        preds = self.forward(tokenized_input).logits\n",
        "        loss = self.loss_fn(preds, labels)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
        "        self.train_AUROC(preds.sigmoid(), labels.long())\n",
        "        self.log('train_AUROC', self.train_AUROC, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        tokenized_input, labels = batch\n",
        "        preds = self.forward(tokenized_input).logits\n",
        "        loss = self.loss_fn(preds, labels)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.val_AUROC(preds.sigmoid(), labels.long())\n",
        "        self.log('val_AUROC', self.val_AUROC, on_step=False, on_epoch=True)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        tokenized_input = batch\n",
        "        preds = self.forward(tokenized_input).logits\n",
        "        preds = preds.sigmoid()\n",
        "        return preds.detach().cpu()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "YIhvXRUvam3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルが学習しているかどうかを確認するには、トレーニング中のパフォーマンスをモニターする必要がある。具体的には、時間の経過とともに損失が減少していること、追跡しているメトリクスに改善が見られることを確認したい。\n",
        "\n",
        "ここでは、TensorBoardを使用してトレーニングを監視します。TensorBoardは、時間の経過とともにモデルのパフォーマンスを可視化する便利なツールです。\n",
        "\n",
        "TensorBoardサーバーを起動するには、以下のセルを実行します。数秒後、インターフェースが表示されます。トレーニングやロギング値を開始していないため、最初は何も出力されません。トレーニングが開始されると、セルの出力は定期的に更新されます。"
      ],
      "metadata": {
        "id": "Jc4w0l0jWvFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "metadata": {
        "id": "OHpyCHfzCfsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "トレーニングの準備はほぼ整いました。次のセルでは、まずデータを学習セットと検証セットに分割し、データをバッチ処理するPyTorchの `DataLoaders` を準備します。次に、モデルとロガーを初期化し、モデルの最適な反復を保存するコールバックを作成します。最後に、学習を開始します。"
      ],
      "metadata": {
        "id": "LPfftHC7YO_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = torch.utils.data.random_split(ds, [0.8, 0.2])\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "model = CustomModel()\n",
        "tb_logger = pl.loggers.TensorBoardLogger('lightning_logs', name='', version='custom_model')\n",
        "if os.path.exists(f'lightning_logs/{tb_logger.version}/checkpoints'):\n",
        "    for checkpoint in os.listdir(f'lightning_logs/{tb_logger.version}/checkpoints/'):\n",
        "        os.remove(f'lightning_logs/{tb_logger.version}/checkpoints/{checkpoint}')\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_AUROC', mode='max')\n",
        "profiler = pl.profilers.AdvancedProfiler(dirpath='.', filename='profile')\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=3, accelerator='gpu', precision='16-mixed',\n",
        "    logger=tb_logger,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    enable_progress_bar=True\n",
        ")\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ],
      "metadata": {
        "id": "w5q3nesc6tiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#9271C3'>予測</font>\n",
        "\n",
        "モデルの学習が終了したら、テストデータの予測を生成することができます。以前のようにデータをトークン化する必要があります。さらに、さまざまなトレーニング・パラメータによっては、モデルが最適な状態にないこともあります。しかし、チェックポイント・コールバックで最適なバージョンを保存したので、簡単にモデルを最適な状態にリロードすることができます。"
      ],
      "metadata": {
        "id": "4rqU322iG_ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "test_ds = CustomDataset(tokenizer, test_data['comment_text'])\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "ckpt_path = glob(f'lightning_logs/{tb_logger.version}/checkpoints/*')[0]\n",
        "model = CustomModel.load_from_checkpoint(ckpt_path)\n",
        "preds = trainer.predict(model, test_dl)"
      ],
      "metadata": {
        "id": "iPe2e6KG20Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['id'] = test_data['id']\n",
        "submission[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']] = torch.vstack(preds).numpy()\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "submission"
      ],
      "metadata": {
        "id": "kgZ_MV0I66l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#9271C3'>Kaggleへのアップロード</font>\n",
        "\n",
        "予測はKaggleのAPIを通して直接提出されるため、ファイルを手動でダウンロードし、Kaggleのウェブサイトに再アップロードする必要はありません。"
      ],
      "metadata": {
        "id": "fG525n1dNuag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f submission.csv -m \"これはアップロードに添付されたメッセージである。\""
      ],
      "metadata": {
        "id": "UPOJEqqI4icH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[提出ページ](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/submissions)でスコアを確認する。"
      ],
      "metadata": {
        "id": "SxzTLDk7MNTn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIcLceBRoLIz"
      },
      "source": [
        "# <font color='#3E1485'>**提案**</font>\n",
        "\n",
        "**他のモデル** - BERT以外にも多くの言語モデルがあります。新しいモデルの方が性能は良いですが、パラメータが多いのでオーバーフィッティングになりやすいかもしれません。\n",
        "\n",
        "**学習率** - 我々の学習率は非常に小さい。これはオーバーフィッティングを避けるのに役立ち、スコアが悪くなる可能性がありますが、訓練時間が長くなります。学習結果を観察し、学習率を上げてみてください。\n",
        "\n",
        "**エポック** - 我々のモデルは3エポックしか学習しません。TensorBoardでトレーニングの進捗を確認すると、検証損失とメトリクスが着実に向上しているように見えますが、これはもっとトレーニングすべき指標です。エポック数を増やしてみましょう。\n",
        "\n",
        "**すべてのパラメータを訓練する** - 現在、分類器の重みのみを更新しており、事前訓練された重みは更新していません。すべての重みを更新することで、より高いスコアが得られますが、オーバーフィットしやすくなります。さらに、すべてのパラメータをトレーニングすると、トレーニング時間とメモリ要件が増加します。\n",
        "\n",
        "**トレーニングの自動停止** - 多くのエポック数を学習すると、モデルの改善はどこかで止まってしまいます。PyTorch Lightningには、学習を早期に終了させる早期停止コールバックがあります。[ドキュメンテーション](https://lightning.ai/docs/pytorch/stable/common/early_stopping.html)を確認して、学習プロセスに追加できるか確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuRJUK5206XH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}